{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Hate Speech Detection Model\n", "Fine-tuning RoBERTa on the combined hate speech dataset for 3-way classification."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import torch\n", "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n", "from transformers import DataCollatorWithPadding\n", "from datasets import Dataset\n", "from sklearn.metrics import accuracy_score, f1_score, classification_report"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load and Prepare Data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load the cleaned and encoded combined dataset\n", "df = pd.read_csv(\"combined_hate_speech_dataset.csv\")\n", "df['label_encoded'] = pd.factorize(df['label'])[0]  # Ensure encoding if not saved before\n", "\n", "# Train/Val/Test split\n", "from sklearn.model_selection import train_test_split\n", "train_df, temp_df = train_test_split(df, stratify=df['label_encoded'], test_size=0.2, random_state=42)\n", "val_df, test_df = train_test_split(temp_df, stratify=temp_df['label_encoded'], test_size=0.5, random_state=42)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Convert to Hugging Face Datasets"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_dataset = Dataset.from_pandas(train_df[['text', 'label_encoded']])\n", "val_dataset = Dataset.from_pandas(val_df[['text', 'label_encoded']])\n", "test_dataset = Dataset.from_pandas(test_df[['text', 'label_encoded']])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load RoBERTa Model and Tokenizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_name = \"roberta-base\"\n", "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n", "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Tokenization Function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def tokenize_function(examples):\n", "    return tokenizer(examples[\"text\"], truncation=True)\n", "\n", "train_dataset = train_dataset.map(tokenize_function, batched=True)\n", "val_dataset = val_dataset.map(tokenize_function, batched=True)\n", "test_dataset = test_dataset.map(tokenize_function, batched=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Define Metrics"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def compute_metrics(eval_pred):\n", "    logits, labels = eval_pred\n", "    predictions = np.argmax(logits, axis=-1)\n", "    return {\n", "        \"accuracy\": accuracy_score(labels, predictions),\n", "        \"f1_macro\": f1_score(labels, predictions, average='macro')\n", "    }"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Training Arguments"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["training_args = TrainingArguments(\n", "    output_dir=\"./results\",\n", "    evaluation_strategy=\"epoch\",\n", "    save_strategy=\"epoch\",\n", "    learning_rate=2e-5,\n", "    per_device_train_batch_size=16,\n", "    per_device_eval_batch_size=16,\n", "    num_train_epochs=3,\n", "    weight_decay=0.01,\n", "    load_best_model_at_end=True,\n", "    metric_for_best_model=\"f1_macro\",\n", ")\n", "\n", "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train the Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["trainer = Trainer(\n", "    model=model,\n", "    args=training_args,\n", "    train_dataset=train_dataset,\n", "    eval_dataset=val_dataset,\n", "    tokenizer=tokenizer,\n", "    data_collator=data_collator,\n", "    compute_metrics=compute_metrics\n", ")\n", "\n", "trainer.train()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Evaluate on Test Set"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["predictions = trainer.predict(test_dataset)\n", "y_true = predictions.label_ids\n", "y_pred = np.argmax(predictions.predictions, axis=1)\n", "print(classification_report(y_true, y_pred))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 2}